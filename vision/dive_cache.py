"""Dive Cache - Multi-Level Intelligent Caching
10-100x faster repeated operations
"""
import time, json, sqlite3, hashlib, threading
from pathlib import Path
from typing import Any, Optional
from collections import OrderedDict

class DiveCache:
    def __init__(self, memory_size=1000, disk_path="cache/dive_cache.db"):
        self.memory_size, self.disk_path = memory_size, Path(disk_path)
        self.disk_path.parent.mkdir(parents=True, exist_ok=True)
        self._memory_cache, self._lock = OrderedDict(), threading.Lock()
        self._init_disk_cache()
        self.stats = {"hits": 0, "misses": 0, "memory_hits": 0, "disk_hits": 0, "sets": 0}
        print(f"âœ… Dive Cache initialized")
    
    def _init_disk_cache(self):
        conn = sqlite3.connect(str(self.disk_path))
        conn.execute("CREATE TABLE IF NOT EXISTS cache (key TEXT PRIMARY KEY, value TEXT, created_at REAL, accessed_at REAL, ttl REAL)")
        conn.execute("CREATE INDEX IF NOT EXISTS idx_accessed ON cache(accessed_at)")
        conn.commit()
        conn.close()
    
    def get(self, key: str) -> Optional[Any]:
        with self._lock:
            if key in self._memory_cache:
                self._memory_cache.move_to_end(key)
                self.stats["hits"] += 1
                self.stats["memory_hits"] += 1
                return json.loads(self._memory_cache[key])
        conn = sqlite3.connect(str(self.disk_path))
        row = conn.execute("SELECT value, ttl, created_at FROM cache WHERE key = ?", (key,)).fetchone()
        if row:
            value_json, ttl, created_at = row
            if ttl > 0 and (time.time() - created_at) > ttl:
                conn.execute("DELETE FROM cache WHERE key = ?", (key,))
                conn.commit()
                conn.close()
                self.stats["misses"] += 1
                return None
            conn.execute("UPDATE cache SET accessed_at = ? WHERE key = ?", (time.time(), key))
            conn.commit()
            conn.close()
            value = json.loads(value_json)
            with self._lock:
                self._memory_cache[key] = value_json
                if len(self._memory_cache) > self.memory_size:
                    self._memory_cache.popitem(last=False)
            self.stats["hits"] += 1
            self.stats["disk_hits"] += 1
            return value
        conn.close()
        self.stats["misses"] += 1
        return None
    
    def set(self, key: str, value: Any, ttl: float = 3600):
        value_json, now = json.dumps(value), time.time()
        with self._lock:
            self._memory_cache[key] = value_json
            if len(self._memory_cache) > self.memory_size:
                self._memory_cache.popitem(last=False)
        conn = sqlite3.connect(str(self.disk_path))
        conn.execute("INSERT OR REPLACE INTO cache (key, value, created_at, accessed_at, ttl) VALUES (?, ?, ?, ?, ?)", 
                    (key, value_json, now, now, ttl))
        conn.commit()
        conn.close()
        self.stats["sets"] += 1
    
    def get_stats(self):
        total = self.stats["hits"] + self.stats["misses"]
        hit_rate = (self.stats["hits"] / total * 100) if total > 0 else 0
        return {**self.stats, "total_requests": total, "hit_rate": f"{hit_rate:.1f}%"}
